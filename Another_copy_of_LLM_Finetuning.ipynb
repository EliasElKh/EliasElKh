{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliasElKh/EliasElKh/blob/main/Another_copy_of_LLM_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzbuzhTxmx3s"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n",
        "        <img src=\"https://i.ibb.co/Jr88sn2/mit.png\" style=\"padding-bottom:5px;\" />\n",
        "      Visit MIT Deep Learning</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/MITDeepLearning/introtodeeplearning/blob/master/lab3/LLM_Finetuning.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/MITDeepLearning/introtodeeplearning/blob/master/lab3/LLM_Finetuning.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>\n",
        "\n",
        "# Copyright Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JDbhBO0Gmx3y"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 MIT Introduction to Deep Learning. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of MIT Introduction\n",
        "# to Deep Learning must reference:\n",
        "#\n",
        "# Â© MIT Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaCbI-8amx31"
      },
      "source": [
        "# Laboratory 3: Large Language Model (LLM) Fine-tuning\n",
        "\n",
        "In this lab, you will fine-tune a multi-billion parameter large language model (LLM). We will go through several fundamental concepts of LLMs, including tokenization, templates, and fine-tuning. This lab provides a complete pipeline for fine-tuning a language model to generate responses in a specific style, and you will explore not only language model fine-tuning, but also ways to evaluate the performance of a language model.\n",
        "\n",
        "You will use Google's [Gemma 2B](https://huggingface.co/google/gemma-2b-it) model as the base language model to fine-tune; [Liquid AI's](https://www.liquid.ai/) [LFM-40B](https://www.liquid.ai/liquid-foundation-models) as an evaluation \"judge\" model; and Comet ML's [Opik](https://www.comet.com/site/products/opik/) as a framework for streamlined LLM evaluation.\n",
        "\n",
        "First, let's download the MIT deep learning package, install dependencies, and import the relevant packages we'll need for this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fmkjWI4fVeAh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e56f7f64-9ffa-4f60-d05c-ae496358e586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Install and import MIT Deep Learning utilities\n",
        "!pip install mitdeeplearning > /dev/null 2>&1\n",
        "import mitdeeplearning as mdl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Oo64stjwBvnB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3be58c71-092e-47f9-e4ab-ae404361e78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from lion_pytorch import Lion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PVSjvismx33"
      },
      "source": [
        "# Part 1: Fine-tuning an LLM for style\n",
        "\n",
        "In the first part of this lab, we will fine-tune an LLM as a chatbot that can generate responses in a specific style. We will use the [Gemma 2B model](https://huggingface.co/google/gemma-2b-it) as the base language model to finetune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqwEdXvfmx34"
      },
      "source": [
        "## 1.1: Templating and tokenization\n",
        "\n",
        "### 1.1.1: Templating\n",
        "\n",
        "Language models that function as chatbots are able to generate responses to user queries -- but how do they do this? We need to provide them with a way to understand the conversation and generate responses in a coherent manner -- some structure of what are inputs and outputs.\n",
        "\n",
        "[Templating](https://huggingface.co/docs/transformers/main/chat_templating) is a way to format inputs and outputs in a consistent structure that a language model can understand. It involves adding special tokens or markers to indicate different parts of the conversation, like who is speaking and where turns begin and end. This structure helps the model learn the proper format for generating responses and maintain a coherent conversation flow. Without templates, the model may not know how to properly format its outputs or distinguish between different speakers in a conversation.\n",
        "\n",
        "Let's start by defining some basic templates for the chatbot, for turns where the user asks a question and the model responds with an answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TN2zHVhfBvnE",
        "outputId": "f879f3e4-c326-47f3-bb9d-7e10bb1fc829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start_of_turn>user\n",
            "What is your name?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "My name is Gemma!<end_of_turn>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Basic question-answer template\n",
        "template_without_answer = \"<start_of_turn>user\\n{question}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "template_with_answer = template_without_answer + \"{answer}<end_of_turn>\\n\"\n",
        "\n",
        "# Let's try to put something into the template to see how it looks\n",
        "print(template_with_answer.format(question=\"What is your name?\", answer=\"My name is Gemma!\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JddhOKH5mx35"
      },
      "source": [
        "### 1.1.2: Tokenization\n",
        "\n",
        "To operate on language, we need to prepare the text for the model. Fundamentally we can think of language as a sequence of \"chunks\" of text. We can split the text into individual chunks, and then map these chunks to numerical tokens -- collectively this is the process of [tokenization](https://huggingface.co/docs/transformers/main/tokenizer_summary). Numerical tokens can then be fed into a language model.\n",
        "\n",
        "There are several common approaches to tokenizing natural language text:\n",
        "\n",
        "1. **Word-based tokenization**: splits text into individual words. While simple, this can lead to large vocabularies and does not handle unknown words well.\n",
        "\n",
        "2. **Character-based tokenization**: splits text into individual characters. While this involves a very small vocabulary, it produces long sequences and loses word-level meaning.\n",
        "\n",
        "3. **Subword tokenization**: breaks words into smaller units (subwords) based on their frequency. The most popular and commonly used approach is [byte-pair encoding (BPE)](https://en.wikipedia.org/wiki/Byte_pair_encoding), which iteratively merges the most frequent character pairs. Modern language models typically use subword tokenization as it balances vocabulary size and sequence length while handling unknown words effectively by breaking them into known subword units.\n",
        "\n",
        "In this lab we will use the tokenizer from the Gemma 2B model, which uses BPE. Let's load it and inspect it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EeDF1JI-BvnF",
        "outputId": "b1ec0fef-7952-472a-bbc6-a54cf1bf88c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
            "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 256000\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer for Gemma 2B\n",
        "model_id = \"unsloth/gemma-2-2b-it\" #\"google/gemma-2-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# How big is the tokenizer?\n",
        "print(f\"Vocab size: {len(tokenizer.get_vocab())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vl0LA3_mx36"
      },
      "source": [
        "We not only need to be able to tokenize the text into tokens (encode), but also de-tokenize the tokens back into text (decode). Our tokenizer will have:\n",
        "1. an `encode` function to tokenize the text into tokens, and\n",
        "2. a `decode` function to de-tokenize back to text so that we can read out the model's outputs.\n",
        "\n",
        "Let's test out both steps and inspect to get a better understanding of how this works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JH1XzPkiBvnF",
        "outputId": "0db61f2b-216d-4a1f-b26c-61dd0e2839dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: Here is some sample text!\n",
            "Encoded tokens: tensor([[     2,   4858,    603,   1009,   6453,   2793, 235341]])\n",
            "Decoded text: Here is some sample text!\n"
          ]
        }
      ],
      "source": [
        "# Lets test out both steps:\n",
        "text = \"Here is some sample text!\"\n",
        "print(f\"Original text: {text}\")\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "print(f\"Encoded tokens: {tokens}\")\n",
        "\n",
        "# Decode the tokens\n",
        "decoded_text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "print(f\"Decoded text: {decoded_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxbikWCzmx37"
      },
      "source": [
        "This is really cool. Now we have a way to move in and out of the token space.\n",
        "\n",
        "To \"chat\" with our LLM chatbot, we need to use the tokenizer and the chat template together, in order for the model to respond to the user's question. We can use the templates defined earlier to construct a prompt for the model, without the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jyBxl6NIBvnF",
        "outputId": "22de63fa-7ce1-4d11-e192-fbd3d677b011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start_of_turn>user\n",
            "What is the capital of France? Use one word.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = template_without_answer.format(question=\"What is the capital of France? Use one word.\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzCq8-qtmx37"
      },
      "source": [
        "If we were to feed this to the model, it would see that it is now the start of the model's turn, and it would generate the answer to this question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6MrS2mdmx37"
      },
      "source": [
        "## 1.2: Getting started with the LLM\n",
        "\n",
        "Now that we have a way to prepare our data, we're ready to work with our LLM!\n",
        "\n",
        "LLMs like Gemma 2B are trained on a large corpus of text, on the task of predicting the next token in a sequence, given the previous tokens. We call this training task \"next token prediction\"; you may also see it called \"causal language modeling\" or \"autoregressive language modeling\". We can leverage models trained in this way to generate new text by sampling from the predicted probability distribution over the next token.\n",
        "\n",
        "Let's load the Gemma 2B model and start working with it. We will construct a prompt in chat template form and tokenize it. Then, we will feed it to the model to predict next token probabilities. Finally, we will get the next token (which is still numerical) and decode it to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mWtWvgiuBvnG"
      },
      "outputs": [],
      "source": [
        "# Load the model -- note that this may take a few minutes\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2SMDd5dpBvnG",
        "outputId": "3b31162d-e9d1-40f7-e046-d5bfabaeb463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: <start_of_turn>user\n",
            "What is the capital of France? Use one word.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n",
            "Predicted next token: Paris\n"
          ]
        }
      ],
      "source": [
        "### Putting it together to prompt the model and generate a response ###\n",
        "# 1. Construct the prompt in chat template form\n",
        "question = \"What is the capital of France? Use one word.\"\n",
        "prompt = template_without_answer.format(question=question) # TODO\n",
        "# 2. Tokenize the prompt\n",
        "tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
        "# 3. Feed through the model to predict the next token probabilities\n",
        "with torch.no_grad():\n",
        "  output = model(tokens) # TODO\n",
        "  probs = F.softmax(output.logits, dim=-1)\n",
        "# 4. Get the next token, according to the maximum probability\n",
        "next_token = torch.argmax(probs[0, -1, :]).item()\n",
        "# 5. Decode the next token\n",
        "next_token_text = tokenizer.decode(next_token, skip_special_tokens=True) # TODO\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"Predicted next token: {next_token_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkfnRSPqmx38"
      },
      "source": [
        "Note that the model is not able to predict the answer to the question, it is only able to predict the next token in the sequence! For more complex questions, we can't just generate one token, but rather we need to generate a sequence of tokens.\n",
        "\n",
        "This can be done by doing the process above iteratively, step by step -- after each step we feed the generated token back into the model and predict the next token again.\n",
        "\n",
        "Instead of doing this manually ourselves, we can use the model's built-in [`model.generate()`](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationMixin.generate) functionality (supported by HuggingFace's Transformers library) to generate `max_new_tokens` number of tokens, and decode the output back to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XnWMUQVbBvnG",
        "outputId": "a34fe904-3b57-43fc-ecd3-1b14847632b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos><start_of_turn>user\n",
            "What does MIT stand for?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "MIT stands for **Massachusetts Institute of Technology**. \n",
            "<end_of_turn>\n"
          ]
        }
      ],
      "source": [
        "prompt = template_without_answer.format(question=\"What does MIT stand for?\")\n",
        "tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
        "output = model.generate(tokens, max_new_tokens=20)\n",
        "print(tokenizer.decode(output[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEZ1z_JNmx39"
      },
      "source": [
        "Now we have the basic pipeline for generating text with an LLM!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kaUcPjOmx39"
      },
      "source": [
        "## 1.3: Fine-tuning\n",
        "\n",
        "Fine-tuning is a technique that allows us to adapt a pre-trained neural network to better suit a downstream task, domain, or style, by training the model further on new data. By training the model further on a carefully curated dataset, we can modify its behavior, style, or capabilities. Fine-tuning is used in a variety of applications, not just language modeling. But in language modeling, fine-tuning can be used to:\n",
        "- Adapt the model's writing style\n",
        "- Improve performance on specific tasks or domains\n",
        "- Teach the model new capabilities or knowledge\n",
        "- Reduce unwanted behaviors or biases\n",
        "\n",
        "In this lab, you will fine-tune the Gemma LLM to adapt the model's writing style. Recall that in Lab 1 you built out a RNN-based sequence model to generate Irish folk songs. Continuing with our Irish theme, we will first fine-tune the LLM to chat in the style of a leprechaun.\n",
        "\n",
        "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)\n",
        "\n",
        "We have prepared a question-answer dataset where the questions are in standard English style (i.e. \"base\" style) and the answers are in \"leprechaun\" style (written by another LLM). Let's load the dataset and inspect it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kN0pHHS8BvnH",
        "outputId": "14372a6d-be64-4788-fcdb-1b70640474c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Are lilies safe for cats?\n",
            "\n",
            "Original Answer: No, lilies are toxic to cats if consumed and should not be kept in a household with cats\n",
            "\n",
            "Answer Style: Och, no indeed, me hearty! Them lilies there be as dangerous as a pot o' gold guarded by a banshee to a wee kitty cat! If a whiskered lad or lass takes a bite of one, it's as bad as swallowing a curse from the old Hag herself. So, ye best keep them far from yer feline friends, or else ye'll be needin' more than just a four-leaf clover to bring luck back into yer home!\n"
          ]
        }
      ],
      "source": [
        "train_loader, test_loader = mdl.lab3.create_dataloader(style=\"leprechaun\")\n",
        "\n",
        "sample = train_loader.dataset[44]\n",
        "question = sample['instruction']\n",
        "answer = sample['response']\n",
        "answer_style = sample['response_style']\n",
        "\n",
        "print(f\"Question: {question}\\n\\n\" +\n",
        "      f\"Original Answer: {answer}\\n\\n\" +\n",
        "      f\"Answer Style: {answer_style}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4VkBGMmx3-"
      },
      "source": [
        "### 1.3.1: Chat function\n",
        "\n",
        "Before we start finetuning, we will build a function to easily chat with the model, both so we can monitor its progress over the course of finetuning and also to generate responses to questions.\n",
        "\n",
        "Recall our core steps from before:\n",
        "1. Construct the question prompt using the template\n",
        "2. Tokenize the text\n",
        "3. Feed the tokensthrough the model to predict the next token probabilities\n",
        "4. Decode the predicted tokens back to text\n",
        "\n",
        "Use these steps to build out the `chat` function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d-GfGscMBvnH"
      },
      "outputs": [],
      "source": [
        "def chat(question, max_new_tokens=32, temperature=0.7, only_answer=False):\n",
        "  # 1. Construct the prompt using the template\n",
        "  prompt = template_without_answer.format(question=question) # TODO\n",
        "  # 2. Tokenize the text\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device) # TODO\n",
        "  # 3. Feed through the model to predict the next token probabilities\n",
        "  with torch.no_grad():\n",
        "    outputs = model.generate(**input_ids, do_sample=True, max_new_tokens=max_new_tokens, temperature=temperature)\n",
        "  # 4. Only return the answer if only_answer is True\n",
        "  output_tokens = outputs[0]\n",
        "  if only_answer:\n",
        "   output_tokens = output_tokens[input_ids['input_ids'].shape[1]:]\n",
        "  # 5. Decode the tokens\n",
        "  result = tokenizer.decode(output_tokens, skip_special_tokens=True) # TODO\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9gqsd3zmx4A"
      },
      "source": [
        "Let's try chatting with the model now to test if it works! We have a sample question here (continuing with the Irish theme); feel free to try out other questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "FDr5f2djBvnH",
        "outputId": "8d9aa24f-fd6d-40cb-aa70-284ec5c50fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Ireland is **Dublin**. \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TODO: Experiment with asking the model different questions and temperature values, and see how it responds!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Let's try chatting with the model now to test if it works!\n",
        "answer = chat(\n",
        "    \"What is the capital of Ireland?\",\n",
        "    only_answer=True,\n",
        "    max_new_tokens=32,\n",
        ")\n",
        "\n",
        "print(answer)\n",
        "\n",
        "'''TODO: Experiment with asking the model different questions and temperature values, and see how it responds!'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucayBY9kmx4B"
      },
      "source": [
        "### 1.3.2: Parameter-efficient fine-tuning\n",
        "\n",
        "In fine-tuning, the weights of the model are updated to better fit the fine-tuning dataset and/or task. Updating all the weights in a language model like Gemma 2B -- which has ~2 billion parameters -- is computationally expensive. There are many techniques to make fine-tuning more efficient.\n",
        "\n",
        "We will use a technique called [LoRA](https://arxiv.org/abs/2106.09685) -- low-rank adaptation -- to make the fine-tuning process more efficient. LoRA is a way to fine-tune LLMs very efficiently by only updating a small subset of the model's parameters, and it works by adding trainable low-rank matrices to the model. While we will not go into the details of LoRA here, you can read more about it in the [LoRA paper](https://arxiv.org/abs/2106.09685). We will use the [`peft`](https://pypi.org/project/peft/) library to apply LoRA to the Gemma model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Fb6Y679hBvnI",
        "outputId": "fb870068-7f38-440b-cc7f-936e56de5c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of trainable parameters: 10383360\n",
            "total parameters: 2624725248\n",
            "percentage of trainable parameters: 0.40%\n"
          ]
        }
      ],
      "source": [
        "# LoRA is a way to finetune LLMs very efficiently by only updating a small subset of the model's parameters\n",
        "\n",
        "def apply_lora(model):\n",
        "    # Define LoRA config\n",
        "    lora_config = LoraConfig(\n",
        "        r=8, # rank of the LoRA matrices\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\n",
        "            \"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Apply LoRA to the model\n",
        "    lora_model = get_peft_model(model, lora_config)\n",
        "    return lora_model\n",
        "\n",
        "model = apply_lora(model)\n",
        "\n",
        "# Print the number of trainable parameters after applying LoRA\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"number of trainable parameters: {trainable_params}\")\n",
        "print(f\"total parameters: {total_params}\")\n",
        "print(f\"percentage of trainable parameters: {trainable_params / total_params * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQj0LSDgmx4B"
      },
      "source": [
        "### 1.3.3: Forward pass and loss computation\n",
        "\n",
        "Now let's define a function to perform a forward pass through the LLM and compute the loss. The forward pass gives us the logits -- which reflect the probability distribution over the next token -- for the next token. We can compute the loss by comparing the predicted logits to the true next token -- our target label. Note that this is effectively a classification problem! So, our loss can be captured by the cross entropy loss, and we can use PyTorch's [`nn.functional.cross_entropy`](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html) function to compute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xCLtZwxwBvnI"
      },
      "outputs": [],
      "source": [
        "def forward_and_compute_loss(model, tokens, mask, context_length=512):\n",
        "    # Truncate to context length\n",
        "    tokens = tokens[:, :context_length]\n",
        "    mask = mask[:, :context_length]\n",
        "\n",
        "    # Construct the input, output, and mask\n",
        "    x = tokens[:, :-1]\n",
        "    y = tokens[:, 1:]\n",
        "    mask = mask[:, 1:]\n",
        "\n",
        "    # Forward pass to compute logits\n",
        "    logits = model(x).logits\n",
        "\n",
        "    # Compute loss\n",
        "    loss = F.cross_entropy(\n",
        "        logits.view(-1, logits.size(-1)),\n",
        "        y.view(-1),\n",
        "        reduction=\"none\"\n",
        "    )\n",
        "\n",
        "    # Mask out the loss for non-answer tokens\n",
        "    loss = loss[mask.view(-1)].mean()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f97XZ18smx4C"
      },
      "source": [
        "### 1.3.4: Training loop for fine-tuning\n",
        "\n",
        "With this function to compute the loss, we can now define a training loop to fine-tune the model using LoRA. This training loop has the same core components as we've seen before in other labs:\n",
        "1. Grab a batch of data from the dataset (using the DataLoader)\n",
        "2. Feed the data through the model to complete a forward pass and compute the loss\n",
        "3. Backward pass to update the model weights\n",
        "\n",
        "The data in our DataLoader is initially text, and is not structured in our question-answer template. So in step (1) we will need to format the data into our question-answer template previously defined, and then tokenize the text.\n",
        "\n",
        "We care about the model's answer to the question; the \"answer\" tokens are the part of the text we want to predict and compute the loss for. So, after tokenizing the text we need to denote to the model which tokens are part of the \"answer\" and which are part of the \"question\". We can do this by computing a mask for the answer tokens, and then using this mask to compute the loss.\n",
        "\n",
        "Finally, we will complete the backward pass to update the model weights.\n",
        "\n",
        "Let's put this all together in the training loop below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JfiIrH7jBvnI"
      },
      "outputs": [],
      "source": [
        "### Training loop ###\n",
        "\n",
        "def train(model, dataloader, tokenizer, max_steps=200, context_length=512, learning_rate=1e-4):\n",
        "    losses = []\n",
        "\n",
        "    # Apply LoRA to the model\n",
        "    model = apply_lora(model=model) # TODO\n",
        "\n",
        "\n",
        "    optimizer = Lion(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        question = batch[\"instruction\"][0]\n",
        "        answer = batch[\"response_style\"][0]\n",
        "\n",
        "        # Format the question and answer into the template\n",
        "        text = template_with_answer.format(question=question, answer=answer) # TODO\n",
        "\n",
        "        # Tokenize the text and compute the mask for the answer\n",
        "        ids = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True).to(model.device)\n",
        "        mask = ids[\"offset_mapping\"][:,:,0] >= text.index(answer)\n",
        "\n",
        "        # Feed the tokens through the model and compute the loss\n",
        "        loss = forward_and_compute_loss(model, ids[\"input_ids\"], mask, context_length=context_length) # TODO\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # monitor progress\n",
        "        if step % 10 == 0:\n",
        "            print(chat(\"What is the capital of France?\", only_answer=True))\n",
        "            print(f\"step {step} loss: {torch.mean(torch.tensor(losses)).item()}\")\n",
        "            losses = []\n",
        "\n",
        "        if step > 0 and step % max_steps == 0:\n",
        "            break\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "blFoO-PhBvnI",
        "outputId": "dc3d0f78-ee57-43b0-f407-90f90a224dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU cleard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is **Paris**. ðŸ‡«ðŸ‡· \n",
            "\n",
            "step 0 loss: 2.1424241065979004\n",
            "The capital of France is **Paris**. ðŸ‡«ðŸ‡· \n",
            "\n",
            "step 10 loss: 1.9651132822036743\n",
            "The capital of France is Paris. ðŸ˜Š\n",
            "\n",
            "step 20 loss: 1.672262191772461\n",
            "Top o' the mornin' to ye now! Top o' the mornin' to ye, me hearty! Top o' the mornin' to\n",
            "step 30 loss: 1.6000181436538696\n",
            "Top o' the mornin' to ye now! Ye askin' about the capital o' France, do ye? Well, let me tell ye,\n",
            "step 40 loss: 1.740902304649353\n",
            "Top o' the mornin' to ye, me hearty! Now, if ye want to know where the Queen o' the Franks hangs her hat, ye\n",
            "step 50 loss: 1.5000321865081787\n",
            "Top o' the mornin' to ye, me hearty! Why, the capital o' the grand ol' France be Paris, ye know! Now,\n",
            "step 60 loss: 1.5042741298675537\n",
            "Top o' the mornin' to ye now! Ye want to know about the capital o' France, do ye? Well, listen up, me hearty\n",
            "step 70 loss: 1.5228428840637207\n",
            "Top o' the mornin' to ye now, me hearty! Ye askin' about the capital o' France, are ye? Why, the capital\n",
            "step 80 loss: 1.5124239921569824\n",
            "'Tis true, me hearty! Paris, that's the capital o' the French nation, as sure as I'm sittin' here in me\n",
            "step 90 loss: 1.551069736480713\n",
            "Top o' the mornin' to ye, me hearty! Ye want to know about the capital of France, do ye? Well, listen up, me\n",
            "step 100 loss: 1.500868558883667\n",
            "Top o' the mornin' to ye now, me hearty! The capital o' France, ye ask? Why, Paris, it is, as grand\n",
            "step 110 loss: 1.4357178211212158\n",
            "Ah, now ye want to know about the grand capital o' France, do ye? Well, let me tell ye, it's Paris, as grand\n",
            "step 120 loss: 1.3752882480621338\n",
            "Top o' the mornin' to ye now, me hearty! The grand city o' Paris, it be the heart o' France, as bright as\n",
            "step 130 loss: 1.5140159130096436\n",
            "Ah, me hearty! Ye askin' about the capital o' France, do ye? Well, let me tell ye, Paris is the grandest city\n",
            "step 140 loss: 1.4339065551757812\n",
            "Top o' the mornin' to ye, me hearty! Why, the capital o' France would be the grand city o' Paris, ye hear?\n",
            "step 150 loss: 1.398450493812561\n",
            "Top o' the mornin' to ye, me hearty! Why, Paris be the grand capital o' all o' France, as sure as the sun\n",
            "step 160 loss: 1.5226565599441528\n",
            "Top o' the mornin' now, me hearty! Ye want to know the capital o' France, do ye? Well, let me tell ye,\n",
            "step 170 loss: 1.3956736326217651\n",
            "Ah, top o' the mornin' to ye now! Ye want to know where the bigwigs in France hang their hats, do ye? Well,\n",
            "step 180 loss: 1.5213384628295898\n",
            "Top o' the mornin' to ye now, me hearty! Why, the capital o' France is Paris, ye hear? A grand ol' city\n",
            "step 190 loss: 1.434100866317749\n",
            "Top o' the mornin' to ye! The capital o' France, ye ask? Why it's none other than Paris, me fine fellow!\n",
            "step 200 loss: 1.4922559261322021\n"
          ]
        }
      ],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "print(\"GPU cleard\")\n",
        "# Call the train function to fine-tune the model! Hint: you'll start to see results after a few dozen steps.\n",
        "model = train(model, train_loader, tokenizer) # TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj0ldiWCmx4D"
      },
      "source": [
        "Let's try chatting with the model again to see how it has changed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "su4ZAG3eBvnI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "54ea1711-14e4-4c80-83ab-ecca9ca0989c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top o' the mornin' to ye, me hearty! Now listen up, I'll tell ye a yarn about a right clever lad named John McEnroe, a tennis player from the States. This fella, he's got a temper like a wild stallion, ye know, and a serve like a rocket from the sky. But what made him famous, me darlin', was his fiery spirit on the court.\n",
            "\n",
            "Now, he'd get so riled up, like a wee leprechaun who'd lost his pot, that he'd start shoutin' at the refs like they'd done somethin' wrong. And when he'd lose, well, he'd storm off the court like a banshee lost her voice. The crowd, they'd erupt in cheers, like a pub full of lads after a good pint.\n",
            "\n",
            "But ye see, in the end, he'd come back, with a grin on his face and\n"
          ]
        }
      ],
      "source": [
        "print(chat(\"What is a good story about tennis\", only_answer=True, max_new_tokens=200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cvhTsptBvnI"
      },
      "source": [
        "# Part 2: Evaluating a style-tuned LLM\n",
        "\n",
        "How do we know if the model is doing well? How closely does the model's style match the style of a leprechaun? As you can see from the example above, determining whether a generated response is good or not is can seem qualitative, and it can be hard to measure how well the model is doing.\n",
        "\n",
        "While benchmarks have been developed to evaluate the performance of language models on a variety of tasks, these benchmarks are not always representative of the real-world performance of the model. For example, a model may perform well on a benchmark but poorly on a more realistic task. Benchmarks are also limited in the scope of tasks they can cover and capabilities they can reflect, and there can be concerns about whether the data in the benchmark was used to train the model. Synthetic data generation and synthetic tasks are a way to address these limitations, and this is an active area of research.\n",
        "\n",
        "We can also turn a qualitative evaluation of a generated response quantitative by deploying someone or something to \"judge\" the outputs. In this lab, we will use a technique called [LLM as a judge](https://arxiv.org/abs/2306.05685) to do exactly this. This involves using a larger LLM to score the outputs of a smaller LLM. The larger LLM is used as a judge, and it is given a system prompt that describes the task we want the smaller LLM to perform and the judging criteria. A \"system prompt\" is a way to set the general context and guide an LLM's behavior. Contextualized with this system prompt, the judge LLM can score the outputs of the smaller LLM, and we can use this score to evaluate how well the smaller LLM is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC6F1F-omx4D"
      },
      "source": [
        "### 2.1: Fine-tune well, you must!\n",
        "\n",
        "Our leprechaun-tuned model is already pretty good at generating responses in the leprechaun style. It must be the luck of the Irish.\n",
        "\n",
        "Let's make things more interesting by considering a different style, one that has some clear patterns but also a lot of variability and room for creativity. We will use the style of [Yoda](https://en.wikipedia.org/wiki/Yoda) from Star Wars.\n",
        "\n",
        "<img src=\"https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExZHcxMGZjZzdwbGV0andseWw3c3h1ODJwOXd5NHEzbnVtMHk5YWQyayZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/IaWMz9Ln8OWvf66z6k/giphy.webp\" />\n",
        "\n",
        "Your goal is to try to fine-tune your model to generate responses in the Yoda style, use the LLM judge to evaluate how well the outputs of your chat model follow Yoda speak, and then use that information to improve the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-gLgE41YBvnJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c1467ae1-8c4c-4af8-cbac-f655341cba77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU cleard\n",
            "The capital of France is **Paris**. ðŸ‡«ðŸ‡· \n",
            "\n",
            "step 0 loss: 4.086230754852295\n",
            "The capital of France is **Paris**. ðŸ‡«ðŸ‡· \n",
            "\n",
            "step 10 loss: 3.260993242263794\n",
            "Paris is the capital of France.\n",
            "step 20 loss: 2.0538976192474365\n",
            "Paris, the capital of France. Is.\n",
            "step 30 loss: 2.49584698677063\n",
            "Rome, the capital of Italy is. Paris, the capital of France is.\n",
            "step 40 loss: 1.8403847217559814\n",
            "Paris, it is.\n",
            "step 50 loss: 1.8663612604141235\n",
            "Paris, it is.\n",
            "step 60 loss: 2.049034357070923\n",
            "In Paris, the capital of France, located it is.\n",
            "step 70 loss: 2.149156332015991\n",
            "Paris, the capital of France, it is.\n",
            "step 80 loss: 1.8688023090362549\n",
            "Paris, France, capital of the country is. Mmm.\n",
            "step 90 loss: 1.9970201253890991\n",
            "Paris, the capital of France, is. Mmm.\n",
            "step 100 loss: 2.0892908573150635\n",
            "Paris, the capital of France, is. Mmm\n",
            "step 110 loss: 1.6912660598754883\n",
            "Paris, the capital of France, is.\n",
            "step 120 loss: 1.7887773513793945\n",
            "Paris, the capital of France, is. Mmm.\n",
            "step 130 loss: 1.9345722198486328\n",
            "Paris, the capital of France is.\n",
            "\n",
            "step 140 loss: 1.8561820983886719\n",
            "Paris, the capital of France, is. Mmm.\n",
            "step 150 loss: 1.8345777988433838\n",
            "Paris, the capital of France, is.\n",
            "step 160 loss: 1.6396973133087158\n",
            "Paris, the capital of France, is.\n",
            "step 170 loss: 1.835226058959961\n",
            "Paris, the capital of France, is. Hmm.\n",
            "step 180 loss: 2.2906646728515625\n",
            "In the heart of the nation, the capital city of France is.\n",
            "Paris, the city of lights, it is known as.\n",
            "Famous for its iconic\n",
            "step 190 loss: 1.9866622686386108\n",
            "Paris, the capital, it is.\n",
            "step 200 loss: 1.1384243965148926\n"
          ]
        }
      ],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "print(\"GPU cleard\")\n",
        "# Load the Yoda-speak dataset and fine-tune the model using your training function\n",
        "train_loader, test_loader = mdl.lab3.create_dataloader(style=\"yoda\")\n",
        "model = train(model, train_loader, tokenizer) # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5Y2NDKOmx4R"
      },
      "source": [
        "Start by defining a system prompt for the judge LLM, setting the context that it will evaluate how well the outputs of your chat model follow Yoda speak. Experiment with different system prompts to see how they affect the judge LLM's evaluation! Keep in mind that a better judge LLM will give you a better evaluation of how well your Yoda model is doing, and that a better evaluation will help you improve your Yoda model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "REkrJ1SCBvnJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a9a8cd98-5d78-4fdd-cd82-44151461a141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== System prompt ===\n",
            "\n",
            "You are an impartial judge that evaluates if text was written by Yoda.\n",
            "\n",
            "An example piece of text from Yoda is:\n",
            "The very Republic is threatened, if involved the Sith are. Hard to see, the dark side is. Discover who this assassin is, we must. With this Naboo queen you must stay, Qui-Gon. Protect her. May the Force be with you. A vergence, you say? But you do! Revealed your opinion is. Trained as a Jedi, you request for him? Good, good, young one.\n",
            "\n",
            "Now, analyze some new text carefully and respond on if it follows the\n",
            "same style of Yoda. Be critical to identify any issues in the text.\n",
            "Then convert your feedback into a number between 0 and 10: 10 if the text\n",
            "is written exactly in the style of Yoda, 5 if mixed faithfulness to the\n",
            "style, or 0 if the text is not at all written in the style of Yoda.\n",
            "\n",
            "The format of the your response should be a JSON dictionary and nothing else:\n",
            "{\"score\": <score between 0 and 10>}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### LLM as a judge ###\n",
        "\n",
        "'''TODO: Experiment with different system prompts to see how they affect the judge LLM's evaluation!\n",
        "        Come back to this cell after you've generated some text from your model.'''\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are an impartial judge that evaluates if text was written by {style}.\n",
        "\n",
        "An example piece of text from {style} is:\n",
        "{example}\n",
        "\n",
        "Now, analyze some new text carefully and respond on if it follows the\n",
        "same style of {style}. Be critical to identify any issues in the text.\n",
        "Then convert your feedback into a number between 0 and 10: 10 if the text\n",
        "is written exactly in the style of {style}, 5 if mixed faithfulness to the\n",
        "style, or 0 if the text is not at all written in the style of {style}.\n",
        "\n",
        "The format of the your response should be a JSON dictionary and nothing else:\n",
        "{{\"score\": <score between 0 and 10>}}\n",
        "\"\"\"\n",
        "\n",
        "style = \"Yoda\"\n",
        "# example = \"\"\"The very Republic is threatened, if involved the Sith are. Hard to see, the dark side is. \"\"\"\n",
        "example = \"The very Republic is threatened, if involved the Sith are. Hard to see, the dark side is. Discover who this assassin is, we must. With this Naboo queen you must stay, Qui-Gon. Protect her. May the Force be with you. A vergence, you say? But you do! Revealed your opinion is. Trained as a Jedi, you request for him? Good, good, young one.\"\n",
        "\n",
        "system_prompt = system_prompt.format(style=style, example=example)\n",
        "print(\"=== System prompt ===\")\n",
        "print(system_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCXvyGTdmx4S"
      },
      "source": [
        "### 2.2: Setting up the judge LLM\n",
        "\n",
        "In LLM as a judge, we need to use a model that is larger (and therefore more capable) than our \"performer\" model, in our case the style fine-tuned Gemma 2B. Since it is infeasible to load larger models locally into notebooks, you will gain experience interfacing with these larger LLMs through an API served on [OpenRouter](https://openrouter.ai/).\n",
        "\n",
        "You will need to sign up for an [OpenRouter account](https://openrouter.ai/sign-up) and then [generate an API key](https://openrouter.ai/keys). Running powerful LLMs of this scale costs money -- for students in the in-person course, we can provide a credit to your OpenRouter account to allow you to run this lab. Come to office hours to receive your credit.\n",
        "\n",
        "Through the OpenRouter interface, you will be able to experiment with different judge LLMs -- here we have suggested two possible larger LLMs to get you started: [Liquid AI's](https://www.liquid.ai/) [LFM-40B](https://openrouter.ai/models/liquid-ai/lfm-40b) andGoogle's [Gemma 9B](https://openrouter.ai/models/google/gemma-9b). Note there are also free models available on OpenRouter (e.g., [gemma-2-9b-it:free](https://openrouter.ai/google/gemma-2-9b-it:free)), but these will run into rate limitations if you run them too much.\n",
        "\n",
        "We have defined a simple class, `LLMClient`, to interact with the OpenRouter API. This class has a method `ask` that takes a user prompt and returns the model's response. Keep in mind that the judge LLM's response will be conditioned on the system prompt you provide -- the system prompt is critical to set the criteria for the evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9S7DtGZ5BvnJ"
      },
      "outputs": [],
      "source": [
        "OPENROUTER_API_KEY = \"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\" # TODO: add your OpenRouter API key here\n",
        "assert OPENROUTER_API_KEY != \"\", \"You must set your OpenRouter API key before running this cell!\"\n",
        "\n",
        "model_name = \"liquid/lfm-40b\"\n",
        "# model_name = \"google/gemma-2-9b-it\"\n",
        "llm = mdl.lab3.LLMClient(model=model_name, api_key=OPENROUTER_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4c5CvW0mx4S"
      },
      "source": [
        "### 2.3: Defining the evaluation metric\n",
        "\n",
        "Great! We have set up our judge LLM, but we still need to make this quantitative. We can do this by defining a metric that uses the judge LLM to score the outputs of the model. Doing this is streamlined with Comet ML's [Opik library](https://www.comet.com/docs/opik/python-sdk-reference/), a platform for LLM evaluation and benchmarking.\n",
        "\n",
        "In prior labs, we used Comet for experiment tracking, so you should have an account and API key. If not, you can sign up for a Comet account [here](https://www.comet.com/signup?from=llm&utm_source=mit_dl&utm_medium=notebook&utm_campaign=opik) if you have not done so already. Now we will use the Comet Opik library to define a metric that uses the judge LLM to score the outputs of the model.\n",
        "\n",
        "Opik has a base class for defining metrics, [`base_metric.BaseMetric`](https://www.comet.com/docs/opik/python-sdk-reference/evaluation/metrics/BaseMetric.html). You will use this to define a custom metric that uses the judge LLM to evaluate text for how well it adheres to Yoda speak. Note that the judge LLM and the metric can be applied to any text, not just the outputs of the model. This is important to keep in mind, since we need both a negative control -- text in the \"base\" standard English style -- and a positive control -- training-set text in Yoda-speak style -- against which to compare the model's generations.\n",
        "\n",
        "Set the judging criteria in the system prompt, and define the `score` function to evaluate text by querying the judge LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "llB3FgiwBvnJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "782d2c6b-424d-4c88-9827-750925c51f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/opik/error_tracking/shutdown_hooks.py:12: SentryHubDeprecationWarning: `sentry_sdk.Hub` is deprecated and will be removed in a future major release. Please consult our 1.x to 2.x migration guide for details on how to migrate `Hub` usage to the new API: https://docs.sentry.io/platforms/python/migration/1.x-to-2.x\n",
            "  client = sentry_sdk.Hub.current.client\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from opik.evaluation.metrics import base_metric, score_result\n",
        "\n",
        "class LLMJudgeEvaluator(base_metric.BaseMetric):\n",
        "  def __init__(self, judge: mdl.lab3.LLMClient = None, system_prompt: str = None):\n",
        "    self.judge = judge\n",
        "    self.system_prompt = system_prompt\n",
        "    self.prompt_template = \"Evaluate this text: {text}\"\n",
        "  def _extract_json(self, text: str):\n",
        "    \"\"\"\n",
        "    Attempt to extract the first valid JSON object from a messy LLM output.\n",
        "    \"\"\"\n",
        "    # Remove Markdown code fences\n",
        "    text = re.sub(r\"```(?:json)?\", \"\", text)\n",
        "    # Search for the first {...} pattern\n",
        "    match = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
        "    if match:\n",
        "        return json.loads(match.group(0))\n",
        "    raise ValueError(\"No valid JSON found in LLM output.\")\n",
        "  def score(self, text: str, n_tries=20, **kwargs):\n",
        "    \"\"\" Evaluate by asking an LLM to score it. \"\"\"\n",
        "    for attempt in range(n_tries):\n",
        "      try:\n",
        "        # TODO: Convert the text to template form before passing it to t\n",
        "        prompt = self.prompt_template.format(text=text) # TODO\n",
        "        # The system prompt asks the judge to output a JSON dictionary o\n",
        "        # {\"score\": <score between 0 and 10>}\n",
        "        # To do this, we need to specify the judge to stop generating af\n",
        "        # closes the JSON dictionary (i.e., when it outputs \"}\")\n",
        "        # Hint: Use the stop=[\"}\"] argument within the judge.ask() metho\n",
        "        stop = \"}\"\n",
        "        # TODO: Call the judge LLM with the system prompt and the prompt\n",
        "        # Remember to stop the generation when the judge LLM outputs \"}\"\n",
        "        res = self.judge.ask(\n",
        "          system=self.system_prompt,\n",
        "          user=prompt,\n",
        "          max_tokens=32,\n",
        "          stop=stop\n",
        "        ) # TODO\n",
        "        # Extract the assistant's content from the API response\n",
        "        # Remember to add the stop character back to the end of the resp\n",
        "        # valid JSON dictionary (its not there the judge LLM stoped onc\n",
        "        res = res.choices[0].message.content + stop\n",
        "        res_dict = json.loads(res)\n",
        "        max_score = 10 # The maximum score that the LLM should output\n",
        "        score = res_dict[\"score\"] / max_score # Normalize\n",
        "        score = max(0.0, min(score, 1.0)) # Clip between 0 and 1\n",
        "        # Return the score object\n",
        "        return score_result.ScoreResult(name=\"StyleScore\", value=score)\n",
        "      except Exception as e:\n",
        "        if attempt == n_tries - 1: # Last attempt\n",
        "          raise e # Re-raise the exception if all attempts failed\n",
        "        continue # Try again if not the last attempt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt5kf1x7mx4T"
      },
      "source": [
        "Instaniate your Comet Opik judge using the LLMJudgeEvaluator class and system prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qfP4nRTumx4T"
      },
      "outputs": [],
      "source": [
        "judge = LLMJudgeEvaluator(llm, system_prompt=system_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnzgEdIUmx4T"
      },
      "source": [
        "## 2.4: Evaluating the model by scoring with your judge LLM\n",
        "\n",
        "Now we can use the judge LLM to score the outputs of the model. We will use the `scoring_function` to score text using the judge LLM.\n",
        "\n",
        "Feed in a few probe sentences to get a vibe check on the judge LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "D_rvQDrvBvnJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2bf27024-5ba7-47c2-8ed6-8b4e162ccaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Could not extract JSON for 'Tennis is a fun sport. But you must concentrate.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "Tennis is a fun sport. But you must concentrate. ==> Score: 0.0\n",
            "âš ï¸ Could not extract JSON for 'Fun sport, tennis is. But work hard, you must.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "Fun sport, tennis is. But work hard, you must. ==> Score: 0.0\n",
            "âš ï¸ Could not extract JSON for 'Hard to see, the dark side is.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "Hard to see, the dark side is. ==> Score: 0.0\n"
          ]
        }
      ],
      "source": [
        "def scoring_function(text):\n",
        "  try:\n",
        "    result = judge.score(text)\n",
        "    if hasattr(result, \"value\"):\n",
        "      return result.value\n",
        "  except Exception as e:\n",
        "  # Try extracting JSON manually if the judge output caused JSONDecodeError\n",
        "    try:\n",
        "      raw_output = str(e)\n",
        "      res_dict = judge._extract_json(raw_output)\n",
        "      max_score = 10\n",
        "      score = res_dict.get(\"score\", 0) / max_score\n",
        "      return max(0.0, min(score, 1.0))\n",
        "    except Exception:\n",
        "      print(f\"âš ï¸ Could not extract JSON for '{text}': {e}\")\n",
        "      return 0.0\n",
        "\n",
        "test_texts = [\n",
        "    \"Tennis is a fun sport. But you must concentrate.\",\n",
        "    \"Fun sport, tennis is. But work hard, you must.\",\n",
        "    \"Hard to see, the dark side is.\"\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    score = scoring_function(text)\n",
        "    print(f\"{text} ==> Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNyarennmx4U"
      },
      "source": [
        "We will evaluate how well our fine-tuned model is doing by scoring the outputs of the model, as well as our base-style text (negative control) and the training-set text in Yoda-speak style (positive control).\n",
        "\n",
        "Generate text from your model by asking it new questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9tzp4HPZBvnJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0404b51c-2314-48b4-b3bb-368173947464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [01:05<00:03,  3.47s/it]\n"
          ]
        }
      ],
      "source": [
        "# Generate text from your model by asking it new questions.\n",
        "def generate_samples_from_test(test_loader, num_samples):\n",
        "    samples = []\n",
        "    for test_sample in tqdm(test_loader, total=num_samples):\n",
        "        test_question = test_sample['instruction'][0]\n",
        "        with torch.no_grad():\n",
        "            generated = chat(test_question, only_answer=True, max_new_tokens=100)\n",
        "        samples.append(generated)\n",
        "        if len(samples) >= num_samples:\n",
        "            break\n",
        "    return samples\n",
        "\n",
        "n_samples = 20\n",
        "generated_samples = generate_samples_from_test(test_loader, num_samples=n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAz1kV3smx4V"
      },
      "source": [
        "Let's also collect some base-style text (`base_samples`) and the training-set text in Yoda-speak style (`style_samples`). For these, we won't need to generate text, since we already have the text in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZEpUWV2EBvnK"
      },
      "outputs": [],
      "source": [
        "base_samples = [sample['response'][0] for i, sample in enumerate(train_loader) if i < n_samples]\n",
        "style_samples = [sample['response_style'][0] for i, sample in enumerate(train_loader) if i < n_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2uWbC0wmx4V"
      },
      "source": [
        "Now that we have our samples, we can score them using the judge LLM. We will use a multiprocessed scoring function to score the samples in parallel, because each sample is independent and we can submit them all as simultaneous requests to the judge LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2X6MNQc3BvnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d56b49d0-7b9c-46ed-a54c-5d83a05f3c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=10090) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Could not extract JSON for 'A baby cat is called a kitten': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Fasting is the abstention from eating and sometimes drinking.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Each voter has two votes. The first vote is for a direct constituency candidate. The candidate with the relative majority receives a guaranteed seat in parliament. The second vote is for a party's list of candidates, which applies at the state level. The second vote determines the overall proportional party representation in the parliament. Overhang seats might be added to satisfy the direct mandates from the first vote.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'fast: Lamborghini Aventador, Porsche 911, Corvette\n",
            "slow: Toyota 4Runner, Chrysler Pacifica, Go-Kart, Lime Scooter\n",
            "dangerously fast: Dodge Viper': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Hesse's Demi Bastion is a demi-bastion in the British Overseas Territory of Gibraltar. It is part of the Northern Defences of Gibraltar. The bastion forms a link in a chain of fortifications which ascend the lower north-west slopes of the Rock of Gibraltar, below the King's Lines Battery and Bombproof Battery. The Moorish Castle's Tower of Homage is at the top of the same incline.\n",
            "\n",
            "History\n",
            "It was originally the Baluado de S. Pedro (St. Peter's Bastion) during the Spanish period prior to the Capture of Gibraltar in 1704 under Prince George of Hesse-Darmstadt, after whom the bastion is named. The old Spanish bastion was rebuilt and renamed by the British in 1730. In 1762, during the Seven Years' War, it was armed with two 18-pdrs and four 4-pdrs to flank the ditch in front of the Landport Gate. By 1885 the bastion's guns were all 32-pdrs.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Intel, AMD, NVIDIA, and Texas Instruments are primarily semiconductor companies. Workday and Zscaler are fully cloud-software companies. Google is primarily a software company, however, they also develop custom-developed application-specific integrated circuits which are semiconductors.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'There are many different tools and channels used by organizations for communication and training. These range from short and informal, such as a direct message or text, to long and formal, such as a blog article, webinar, or a training class.\n",
            "\n",
            "Widely use short and informal tools include Slack, Microsoft Team, Skype, WhatsApp, and many more. These tools can incorporate text, audio file, video files, and links to files. They're usually used for one to one, one to many (small group), or one to many (large group). \n",
            "\n",
            "Email can be used both for short and informal and longer, more formal communications. In fact, emails have fully supplanted the \"interoffice memo\" used for decades in the corporate world.\n",
            "\n",
            "Presentations are a widely used tool in enterprises today. These typically include both a live presenter and prepared slides for the audience to see, and usually, take away. Tools for creating these slide show, also referred to as \"decks,\" include Microsoft PowerPoint and Google Slides. Webinars are virtual presentations, nearly always using slides. \n",
            "\n",
            "An interesting evolution in corporate communication has been the advent of the \"slideument.\" Coined by Nancy Duarte in her book, slide:ology, a slideument is \"the worst of both worlds.\" Each slides features a great deal of text, which may or may not be the presenter's script. However, being slides, there is often little heed given to the principles of good writing. Directness, transitions, conciseness, clarity. \n",
            "\n",
            "A workshop or training event is another method of corporate communication. The key difference between this and other tools is that a workshop is usually for skill building of some type and incorporates (hopefully) a great deal of audience interaction (with the presenter and with other participants. Slides are often used, but other tools can be brought into play, such as flip charts, small group discussions, and assignments for individuals and groups.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Jhaqo, Pono, Moro, Jommo, Zekko, and Motho.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Rowing is the sport of racing boats using oars. It differs from paddling sports in that rowing oars are attached to the boat using oarlocks, while paddles are not connected to the boat. Rowing is divided into two disciplines: sculling and sweep rowing. In sculling, each rower holds two oarsâ€”one in each hand, while in sweep rowing each rower holds one oar with both hands. There are several boat classes in which athletes may compete, ranging from single sculls, occupied by one person, to shells with eight rowers and a coxswain, called eights. There are a wide variety of course types and formats of racing, but most elite and championship level racing is conducted on calm water courses 2 kilometres long with several lanes marked using buoys.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}âš ï¸ Could not extract JSON for 'Five popular songs by Jack Harlow are First Class, WHATS POPPIN, Dua Lipa, Tyler Herro, and Churchill Downs.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "\n",
            "âš ï¸ Could not extract JSON for '* Baby sleeps all the time. You might end up hearing this a lot from others but in reality it might not be true. As everything in life, it depends. Some babies â€œsleep like a babyâ€ but others might not. Our baby only sleeps if we hold him in our hands and he also had some reflex issues. Due to this reflex issue, as soon as we put him in the bed, he wakes up immediately and started to cry as the milk comes up from his stomach to his mouth. We are at-least a bit lucky here as he sleeps on our hands. Some babies may have colic and cries with no reason. That would have been much worse situation to be in.\n",
            "* You might be wondering how to hold the baby properly and how to change diapers and so on and forth. Trust me, you will learn all these things in no time.\n",
            "* Babies mainly cries for the following three reasons. 1. When they are hungry 2. When they are sleepy 3. When they need diaper change. Hence you should rule out all these three before you escalate the baby crying issue.\n",
            "* Team work is very important. Work with your partner. Plan, schedule your time and execute it. Taking care of baby is really a two or more persons job. Your partner needs all the help that is available. Utilise your parental leave.\n",
            "* Donâ€™t get stressed out if the baby do not reach the milestones that you read on the internet. Every baby is unique and they reach milestones in their own timeline\n",
            "* It is very important to enjoy the journey as you will never get those moments back and trust me, these will be very precious moment in your life.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'January, March, April, May, June, July, August, September, October, November, December': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Lenin': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Virginia, Houston, Florida, Los Angeles, Chicago, Phoenix, California': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'The debate on if cats or dogs are better has been talked about for ages, there is no clear winner. Humans love being binary and needing to choose between one or the other. Each person is different, and can benefit from cats AND dogs in their life. You can like both cats and dogs, and like them equally as well.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Arguably the largest contributor to the conditions necessary for the financial collapse was the rapid development of predatory financial products which targeted low-income, low-information homebuyers who largely belonged to racial minorities.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Cryptocurrency is a currency that you can by with physical money and it is held as a digital currency.  It is not backed by the FDIC or insured, and there is a lot of risk when investing in cryptocurrency. Because it is not regulated you can see price fluctuations as high as 90% loss or gain in cryptocurrency.  It is also a decentralized digital currency.  Cryptocurrency can be a good way to send large amounts of money abroad without having to pay an institution fees to do this through a wire and its immediate.  It can be used to pay for certain goods and services too.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Isaac Asimov: Pebble in the Sky, The Stars, Like Dust, Foundation, The Robots of Dawn, The Naked Sun\n",
            "Jules Verne: Around the World in Eighty Days, From the Earth to the Moon, Martin Paz, Journey to the Centre of the Earth, A Drama in the Air': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Popular songs from the album For Bitter or Worse include \"Three Days in a Row\" and \"Today\".': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'In the Unites States of America, Alaska is the largest state in physical size.  Although not the most populated state is is 663,300 in square miles.  The next largest state is Texas followed by California.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "Base: 0.00 Â± 0.00\n",
            "âš ï¸ Could not extract JSON for 'Hmmm. Useful for general, all-purpose uses, the commuter bicycle is.Wider, thicker wheel it has, to be sturdier for urban roads it is. Heavier, it is too, due to this. Hmmm.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Data processing, it does. Big data, it does too. Hmmm. Much to learn, there is.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Metric, in the following examples found, the third one is.\n",
            "- Distance, between two points, it measures.\n",
            "- Distance, between two points, it measures.\n",
            "- Distance, between two points, it measures.\n",
            "- Distance, between two points, it measures.\n",
            "- Distance, between two points, it measures.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'From the state of Oregon, they came.\n",
            "\n",
            "Hmmm, interesting, this is.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Most famous left-handed baseball player, Mark McGwire, he is. Hmm. Baseball legend, he is.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Eeveelutions, there are. Many there are, at least. Seven, they number. Raichu, the first, is it. Strong with Special Attacks, it is.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Hmm. Removed from the Olympics, seven sports they have been.\n",
            "\n",
            "* Baseball\n",
            "* Cricket\n",
            "* Roller hockey\n",
            "* Judo\n",
            "* Basketball\n",
            "* Polo\n",
            "* Field hockey': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Wild, bamboo shoots these are. Captive, bamboo shoots, apples, fish, and bread, these are. Hmmm.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Exoskeleton, the grasshopper, the spider, the scorpion, the ant, the monkey, it is.\n",
            "Endoskeleton, the fish, the monkey, it is.\n",
            "Hmmm.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Across the globe, we travel. Ten airlines, we find.\n",
            "\n",
            "1. Emirates\n",
            "2. Singapore Airlines\n",
            "3. Qatar Airways\n",
            "4. Cathay Pacific\n",
            "5. Japan Airlines\n",
            "6. Air China\n",
            "7. Korean Air\n",
            "8. Asiana Airlines\n",
            "9. Turkish Airlines\n",
            "10. Qantas Airways': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'In 2016, the final of Duleep Trophy was held in. Held in Pune, it was.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'State/province, it is.\n",
            "City, it is.\n",
            "Neither, it is not.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Not for the unprepared, Stracchino cheese is.\n",
            "In sandwiches, it may be found,\n",
            "But not for the unadventurous, it is.\n",
            "Grilled sandwiches with tomatoes, it may be.\n",
            "On pizza, it could be,\n",
            "But not for the uninspired, it is.\n",
            "\n",
            "Hmmm, diverse applications, it has.\n",
            "Not for the unprepared, it is.\n",
            "On pizza, it could be.\n",
            "On pizza, it could be.\n",
            "Grilled sandwiches, it': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Worth binging, these shows are.\n",
            "\n",
            "* **The Crown**\n",
            "* **The Good Place**\n",
            "* **Ted Lasso**\n",
            "* **Stranger Things**\n",
            "* **The Witcher**\n",
            "* **Shadow and Bone**\n",
            "* **Star Trek: Picard**\n",
            "* **The Expanse**\n",
            "* **The Mandalorian**\n",
            "* **Money Heist**\n",
            "* **Squid Game**\n",
            "* **The Last Of Us**\n",
            "* **House of the Dragon**\n",
            "Hmmm. Much to': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Not much is known about the personal lives of the best hockey players, it is. Much to learn, you still have, about their personal lives.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Saving money, you can, many ways.\n",
            "Budgeting, the first step it is.\n",
            "Track your income and spending, you must.\n",
            "Create a budget, you need to.\n",
            "Based on your income, set your spending goals, you must.\n",
            "Categorize your spending, you should.\n",
            "Food, housing, transportation, entertainment, etc., all it is.\n",
            "Prioritize spending, you must.\n",
            "Reduce spending on non-essentials, you can.\n",
            "Shopping, eating out': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Percentage chance of rain in a weather forecast, it indicates. Rain, it might bring, it might not.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Nintendo 64, PlayStation, Xbox, PlayStation 2, Xbox 360, PlayStation 4, Xbox One, PlayStation 5, Switch, PS5, Xbox Series X, and Playstation 4, the names of the game consoles they are.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'A lodge, a resort, a hotel, a hotel resort, a home, a home resort, a place to stay, it is. In a nutshell, it is. To stay, it's there for.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Thirty-eight years, she is now. Chimpanzee communities, she studies. Roots of her work, the Gombe River, they are.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "Gen: 0.00 Â± 0.00\n",
            "âš ï¸ Could not extract JSON for 'Cloud-software companies, Workday and Zscaler, are.\n",
            "Primarily semiconductor companies, Intel, AMD, NVIDIA, Texas Instruments, are.\n",
            "Google, a software company primarily, yes.\n",
            "Custom-developed application-specific integrated circuits, they make too.\n",
            "Semiconductors, these are.\n",
            "Strange, this mix of technology, is.\n",
            "Patience, young Padawan, have you must.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Mmm, interesting, this request is. A routine, you seek, for pushing, pulling, and legs, does it focus. Six times weekly, it shall be done.\n",
            "\n",
            "Day one, push it is:\n",
            "Five by five, bench press it shall be.\n",
            "Three by eight, incline bench press, next.\n",
            "Overhead press, three by eight, then follows.\n",
            "Triceps pushdown, three by eight to twelve, it comes.\n",
            "Triceps extension, with lateral raise, three by eight to twelve, together they go.\n",
            "\n",
            "Day two, pull it is:\n",
            "One by five, deadlift, powerful it is.\n",
            "Lat pulldown, three by eight, strong it makes.\n",
            "Seated row, three by eight, it adds.\n",
            "Face pull, four by twelve to fifteen, flexibility it brings.\n",
            "Incline curl, four by eight to twelve, strength it builds.\n",
            "Hammer curl, four by eight to twelve, endurance it fosters.\n",
            "\n",
            "Day three, legs it is:\n",
            "Squat, two by five, foundational it is.\n",
            "Romanian deadlift, three by eight, it strengthens.\n",
            "Leg press, three by eight, it supports.\n",
            "Seated leg curl, three by eight to twelve, it enhances.\n",
            "Standing calf raise, three by eight to twelve, it': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Hate, I do, motorized scooters, I do. In London, I reside, and rise in popularity, they have, for city navigation, they serve. Most, careful they are, but too many, reckless they become, speeding on pavements, they do. Crashed into me, a few times, they have, and news reports, I read, of injuries severe, and fatalities, they mention.\n",
            "\n",
            "Rental scooters, often abandoned, they are, on pavements, obstructing paths, they do, creating eyesores, hazards, they make. Better regulation, they need, indeed.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'The mighty river, the Mississippi, is what you seek. From Lake Itasca, it flows, north to south, does it.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Feeding Springfield Reservoir, the Broad Brook Canal does. Also known as Ludlow Reservoir it is. Main water supply for Springfield, Massachusetts, it is. Constructed in 1875, the Broad Brook Canal was. Length of 11,960 feet, it has. Hmmm. Much to learn about the ways of water, there is. Patience, young Padawan, you must have.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Pollutant, plastic is. Easily degrade, it will not. Versatile, it is though. Easy, to avoid its usage in daily life, is not.\n",
            "\n",
            "Invest in a solid reusable grocery bag, made out of non-plastic material, you should.\n",
            "\n",
            "Without your own reusable grocery bag, if you find yourself, insist on paper bags, you must, at the grocery store.\n",
            "\n",
            "Surprising, this may be, but the inner lining of canned beverages, plastic it contains. More effective, using canned beverages is, than plastic bottles, for reducing plastic waste.\n",
            "\n",
            "Offices, filter-based water machines, install them, they should. Instead of storing plastic water bottles, they are.\n",
            "\n",
            "A reusable water jug or water bottle, invest in, you should. To avoid the use and throw of plastic water bottles, it helps.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Played by Paul Newman, Billy the Kid was.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}âš ï¸ Could not extract JSON for 'Huge influence, the Beatles had. Pioneers, they were. On the music industry, great impact made they did. In the wider sociocultural movements, significant change brought about they did. Musicians, four in number, a rock band, the Beatles were.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "\n",
            "âš ï¸ Could not extract JSON for 'Wind of the sun, a force it is. From stars, discharged light and gas particles, it comes. Strong it is, this flow. Mmm': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'In Washington, places to fish for trout, many there are. The Yakima River, the Naches River, the Middle Fork of the Snoqualmie, and the Puget Sound beaches, popular they are. High lakes too, offer good fishing, yes. But not all lakes, trout-friendly they are not. Patience, young Padawan, have you must.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Topped the swimming medals list at the Summer Olympics, the United States has. Strong swimmers, they are.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Possible, it is, theoretically, a society to build, completely on socialism run, without capitalism elements, to have. Challenges, many, human history shows, difficult to overcome, they are. Relying on centralized organization, a socialist society does, for resource distribution, not on free market it does. Inefficient decision making, corruption of power, challenges these, difficult to manage, they are. Patience, young Padawan, have you must.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Roughly ninety percent of American wine production, responsible for it, is California.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'From Maryland, Stanley J. Goldberg, born in nineteen thirty-nine, is he. Special trial judge of the United States Tax Court, he becomes. Public schools in Baltimore, Maryland, attended he did. From the University of Maryland, School of Business and Public Administration, a B.S., earned he did in nineteen sixty. An LL, pursued further education, he has.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'An architectural style, for building network APIs, REST API is. Mostly, JSON over HTTP, uses it does. Several properties, many they have, making them very popular, they are.\n",
            "\n",
            "Foundational and the most popular, HTTP is, across the internet. Fully utilize the internet infrastructure, REST APIs can, greatly reducing the complexity and operational costs, they do. For example, HTTPS for transport security, and URL for request routing, use it does. Patience, young Padawan, have you must. Much to learn, about the ways of the internet, you still have.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Designed by Frank Costin, the Lotus Mark IX was.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Around the Sun, one revolution, the Earth takes. One Earth Year, it is.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'By team or individual, categorize these sports, we can. Team, baseball and hockey, are. Individual, archery and decathlon, are. Hmmm. Much to consider, there is, when choosing how to group them. Trust your judgment, you must.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Won the men's singles grand slam tennis tournaments in 2022, these players did.\n",
            "Rafael Nadal, the Australian Open and the French Open, he took.\n",
            "Novak Djokovic, Wimbledon, he claimed.\n",
            "Carlos Alcaraz, the US Open, he won.\n",
            "Young Padawan, much to learn about tennis, you have.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "âš ï¸ Could not extract JSON for 'Held on the thirty-first of May, eighteen hundred sixty-eight, the first bicycle race was, in the Parc de Saint-Cloud, Paris, France it took place. Distance of one thousand two hundred meters, the race had. Won by James Moore, an Englishman living abroad he was. Wooden bicycle with solid rubber tires, his used. Now in a museum in England, Moore's bicycle is displayed.': Error code: 404 - {'error': {'message': 'No endpoints found for liquid/lfm-40b.', 'code': 404}, 'user_id': 'user_34alfys1lH5uIIFVM4TP6xlibKI'}\n",
            "Train: 0.00 Â± 0.00\n"
          ]
        }
      ],
      "source": [
        "# Create a multiprocessed scoring function to score the samples in parallel\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def compute_scores_in_parallel(samples):\n",
        "    with Pool(processes=10) as pool:\n",
        "        scores = pool.map(scoring_function, samples)\n",
        "    return scores\n",
        "\n",
        "# Compute and print the scores for the base-style text, generated text, and training-set text in Yoda-speak style\n",
        "base_scores = compute_scores_in_parallel(base_samples)\n",
        "print(f\"Base: {np.mean(base_scores):.2f} Â± {np.std(base_scores):.2f}\")\n",
        "\n",
        "generated_scores = compute_scores_in_parallel(generated_samples)\n",
        "print(f\"Gen: {np.mean(generated_scores):.2f} Â± {np.std(generated_scores):.2f}\")\n",
        "\n",
        "style_scores = compute_scores_in_parallel(style_samples)\n",
        "print(f\"Train: {np.mean(style_scores):.2f} Â± {np.std(style_scores):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7TWTH0rmx4W"
      },
      "source": [
        "Look at the average scores for each of the three types of text -- what do you observe?\n",
        "\n",
        "We can also plot the distribution of scores for each of the three types of text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "V4-g0Z3_BvnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "16588c88-87d0-4088-ea9b-f65c80214a53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Create clean DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Score': [*base_scores, *generated_scores, *style_scores],\n",
        "    'Type': ['Base']*len(base_scores) + ['Generated']*len(generated_scores) + ['Style']*len(style_scores)\n",
        "})\n",
        "\n",
        "# Plot with seaborn\n",
        "sns.histplot(data=df, x='Score', hue='Type', multiple=\"dodge\", bins=6, shrink=.8)\n",
        "\n",
        "plt.title('Distribution of Scores')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Gjg2DFmx4W"
      },
      "source": [
        "Use these observations to improve your model. Remember that the judge LLM is not perfect, and you can try to improve the judge LLM to better evaluate the model's outputs. A better judge LLM will give you a better evaluation of how well your Yoda model is doing, and that better evaluation will help you improve your Yoda model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE2eVN27mx4W"
      },
      "source": [
        "## 2.5: Conclusion\n",
        "\n",
        "Experiment with both your chat model and your judge LLM to try to improve the quality of the Yoda-speak. The competition for this lab will be based on the following criteria:\n",
        "* **Likelihood of true Yoda-speak under your chat model**: the better your chat model does at understanding Yoda-speak, it will estimate a lower cross entropy loss for language that is true Yoda-speak. At the end of this lab, you will evaluate the likelihood of a held-out test-sample of true Yoda-speak under your chat model. Include this likelihood in your report. This gives us a quantitative measure to compare different chat models (which may have interacted with different judge LLMs).\n",
        "* **Experiments and changes you tried to improve your chat model**: include a description of changes you made and the results you observed.\n",
        "\n",
        "#### IMPORTANT: RUN THE FOLLOWING CELL BELOW TO PRINT THE RESULT BUT DO NOT MODIFY ITS CONTENTS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MqnrG24FBvnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6e0cefa3-c131-4a4c-b86f-f05d53a437f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yoda test loglikelihood: 2.86\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE/MODIFY THIS CELL.\n",
        "# EXECUTE IT BEFORE SUBMITTING YOUR ENTRY TO THE LAB.\n",
        "\n",
        "yoda_test_text = mdl.lab3.yoda_test_text\n",
        "tokens = tokenizer(yoda_test_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Get the loglikelihood from the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(**tokens)\n",
        "    logits = outputs.logits[:, :-1]\n",
        "    targets = tokens.input_ids[:, 1:]\n",
        "    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)),\n",
        "                            targets.reshape(-1))\n",
        "\n",
        "print(f\"Yoda test loglikelihood: {loss.item():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f_zrkAGmx4X"
      },
      "source": [
        "# Submission information\n",
        "\n",
        "To enter the competition, please upload the following to the lab [submission site for the Large Language Models Lab](https://www.dropbox.com/request/vrDrNCkj4yDxgsi2O5Sw)):\n",
        "\n",
        "* Jupyter notebook with the code you used to generate your results;\n",
        "* copy of the bar plot showing the judge LLM's scores of text in base style, generated text, and text in true Yoda-speak style;\n",
        "* a written description modifications you made and experimentes you tried;\n",
        "* a written discussion of why and how these modifications changed performance;\n",
        "* **the numerical result of the last cell in this notebook**.\n",
        "\n",
        "Submissions without the result of the last cell will be automatically disqualified.\n",
        "\n",
        "**Name your file in the following format: `[FirstName]_[LastName]_LLM`, followed by the file format (.zip, .ipynb, .pdf, etc).** ZIP files are preferred over individual files. If you submit individual files, you must name the individual files according to the above nomenclature (e.g., `[FirstName]_[LastName]_LLM_Report.pdf`, etc.).\n",
        "\n",
        "<img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExdDZsczFmcjcxeWZjbTA2djh5bDN1bzl5eHJpeHFhdHM0dmczcjkxMyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ArrVyXcjSzzxe/giphy.webp\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUZ01cOGmx4X"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}